{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open Rendered Output](https://img.shields.io/badge/Rendered%20Output-Open-blue?logo=link&logoColor=white)](https://htmlpreview.github.io/?https://raw.githubusercontent.com/MeteoSwiss/nwp-fdb-polytope-demo/main/examples/snapshots/data_retrieve_from_FDB.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval from FDB and Preprocessing\n",
    "\n",
    "This notebook serves as a guide to accessing data from FDB (Fields Database) object storage and preprocessing. In the first part, it demonstrates the computation of median ensembles of precipitations aggregated over 6 hours, followed by a more complex computational process, the computation of potential vorticity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "  <img src=\"https://raw.githubusercontent.com/MeteoSwiss/nwp-fdb-polytope-demo/main/notebooks/FDB/images/potential_vorticity.png\" style=\"width:50%;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "To access the data from FDB, the kernel of the notebooks configures the necessary libraries and environmental variables. \n",
    "See instruction in [FDB installation](https://github.com/MeteoSwiss/nwp-fdb-polytope-demo/blob/main/README.md#Installation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Data from FDB\n",
    "\n",
    "First we import few libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meteodatalab import mars, mch_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the fdb-utils in order to inspect the data that is present in the ICON-CH1-EPS and ICON-CH2-EPS collections. \n",
    "fdb-utils will return keys and values that can be used in the queries to FDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: BUG TO FIX https://meteoswiss.atlassian.net/browse/APNRZ-831\n",
    "# !fdb-utils list --filter type=\"pf\",step=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The realtime FDB contains the latest 8 runs of ICON-CH1-EPS and the latest 4 runs of ICON-CH2-EPS (so that the previous ~24 hours of forecasts are available). Using fdb-utils you will find an ICON-CH1-EPS forecast reference time every 3 hours and ICON-CH2-EPS forecast reference time every 6 hours. We aim at retrieving the latest forecast started ~12 hours ago. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Current time\n",
    "now = datetime.now()\n",
    "\n",
    "# Subtract 12 hours\n",
    "past_time = now - timedelta(hours=12)\n",
    "\n",
    "# Round down to the nearest multiple of 3\n",
    "rounded_hour = (past_time.hour // 3) * 3\n",
    "rounded_time = past_time.replace(hour=rounded_hour, minute=0, second=0, microsecond=0)\n",
    "\n",
    "# Format as YYYYMMDD and HHMM\n",
    "date = rounded_time.strftime('%Y%m%d')\n",
    "time = rounded_time.strftime('%H%M')\n",
    "date,time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Data\n",
    "\n",
    "Use query functions to retrieve the required data.\n",
    "\n",
    "The request for data is made by specifying the values of MARS keys.\n",
    "MARS keys are derived from GRIB keys and serve as a base for the FDB index.\n",
    "The `meteodatalab.mars` module provides helpers to build valid MARS request in the context of MeteoSwiss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbed runs (PF)\n",
    "request_pf = mars.Request(\n",
    "    param=\"TOT_PREC\",\n",
    "    date=date,\n",
    "    time=time,\n",
    "    number=tuple(range(1, 11)),\n",
    "    type=\"pf\",\n",
    "    step=tuple(str(i) for i in range(10)),\n",
    "    levtype=mars.LevType.SURFACE,\n",
    "    model=mars.Model.ICON_CH1_EPS,\n",
    ")\n",
    "\n",
    "# Control run (CF)\n",
    "request_cf = mars.Request(\n",
    "    param=\"TOT_PREC\",\n",
    "    date=date,\n",
    "    time=time,\n",
    "    type=\"cf\",\n",
    "    step=tuple(str(i) for i in range(10)),\n",
    "    levtype=mars.LevType.SURFACE,\n",
    "    model=mars.Model.ICON_CH1_EPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meteodatalab mars request fills some of the key:values required by FDB with defaults for ICON-CH1-EPS and ICON-CH2-EPS, and provides syntax verification of the request. You can inspect the raw FDB request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_pf.to_fdb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `meteodatalab.mch_model_data` module provides some convenience functions to access model data.\n",
    "Earthkit-data is used in the background to read the data that is being returned from FDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pf = mch_model_data.get_from_fdb(request_pf)\n",
    "ds_cf = mch_model_data.get_from_fdb(request_cf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge control (eps=0) with ensemble (eps=1..N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "ds = {\"TOT_PREC\": xr.concat([ds_cf[\"TOT_PREC\"], ds_pf[\"TOT_PREC\"]], dim=\"eps\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is returned as dictionary of xarray DataArrays where the keys are set to the param short name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing for Computing Median Ensembles\n",
    "\n",
    "We will compute the ensembles median of total precipitation aggregated over 6 hours:\n",
    "\n",
    "### Data Aggregation\n",
    "For aggregation of data over 6-hour intervals `meteodatalab` implements operators that transform the data. \n",
    "\n",
    "Total precipitation of the direct model output of ICON is accumulated from the reference time. We use the `delta` to reaggregate to 6 hour intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from meteodatalab.operators import time_operators as time_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_prec_6h = time_ops.delta(ds[\"TOT_PREC\"], np.timedelta64(6, \"h\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_prec_6h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Calculation\n",
    "\n",
    "Next we compute the ensembles median using the 6h aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tot_prec_6h.isel(lead_time=8).median(dim=\"eps\").clip(min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we plot the results using earthkit-plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from earthkit.plots.geo import bounds, domains\n",
    "from earthkit.plots.styles import Style\n",
    "import earthkit\n",
    "import cartopy.crs as ccrs\n",
    "from plot_utils.load_colormaps import load_ncl_rgb_colors\n",
    "from plot_utils.plot_valid_data_frame import get_valid_data_frame\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the spatial extent of the target grid\n",
    "# (we retain the original ICON-CH1/CH2-EPS domain)\n",
    "xmin, xmax = -0.757, 17.583   # Longitude bounds\n",
    "ymin, ymax = 42.183, 50.583   # Latitude bounds\n",
    "\n",
    "bbox = bounds.BoundingBox(xmin, xmax, ymin, ymax, ccrs.Geodetic())\n",
    "domain = domains.Domain.from_bbox(\n",
    "    bbox=bbox,\n",
    "    name=\"CH2\"\n",
    ")\n",
    "# === Load custom colormap with levels ===\n",
    "colors, levels = load_ncl_rgb_colors(\"precip_1h_11lev\")\n",
    "\n",
    "chart = earthkit.plots.Map(domain=domain)\n",
    "chart.grid_cells(data, x=\"lon\", y=\"lat\", style=Style(colors=colors, levels=levels))\n",
    "\n",
    "# === Add Frame ===\n",
    "frame_polygon = get_valid_data_frame(data)\n",
    "\n",
    "if frame_polygon:\n",
    "    x, y = frame_polygon.exterior.xy\n",
    "    chart.ax.plot(x, y, color='black', linewidth=1, transform=ccrs.PlateCarree())\n",
    "else:\n",
    "    print(\"No valid frame polygon could be computed.\")\n",
    "\n",
    "# === Add Map Features ===\n",
    "chart.land()\n",
    "chart.coastlines()\n",
    "chart.borders()\n",
    "chart.gridlines()\n",
    "\n",
    "# === Annotate Chart ===\n",
    "ref_time = pd.to_datetime(data.coords[\"ref_time\"].values[0]).strftime(\"%Y-%m-%d %H:%M UTC\")\n",
    "lead_time = data.coords[\"lead_time\"].values.astype('timedelta64[h]')\n",
    "\n",
    "title = f\"Hourly Precipitation | {ref_time} (+{lead_time})\"\n",
    "legend_label = f\"tot_prec_6h ({'mm'})\"\n",
    "\n",
    "chart.title(title)\n",
    "chart.legend(label=legend_label)\n",
    "chart.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Vorticity Calculation and Wind Field Rotation\n",
    "\n",
    "This notebook introduces another example that requires a multiple-field FDB request, in order to to compute the potential vorticity (PV) and rotating the wind field, representing a more intricate computational process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Data\n",
    "\n",
    "Utilize query functions to smoothly retrieve the nine required fields spanning all model levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = mars.Request(\n",
    "    param=(\"P\", \"T\", \"U\", \"V\", \"W\", \"QV\", \"QC\", \"QI\"),\n",
    "    date=date,\n",
    "    time=time,\n",
    "    type=\"cf\",\n",
    "    step=7,\n",
    "    levtype=mars.LevType.MODEL_LEVEL,\n",
    "    levelist=tuple(range(1, 82)),\n",
    "    model=mars.Model.ICON_CH1_EPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the height field of the vertical levels. Since this is a constant field, it has some different key values than the previous fields (for example step). Therefore, we issue a separate request to obtain the constant HHL field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_hhl_const = mars.Request(\n",
    "    param=\"HHL\",\n",
    "    date=date,\n",
    "    time=time,\n",
    "    type=\"cf\",\n",
    "    step=0,\n",
    "    levtype=mars.LevType.MODEL_LEVEL,\n",
    "    levelist=tuple(range(1, 82)),\n",
    "    model=mars.Model.ICON_CH1_EPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue the two requests and obtain the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = mch_model_data.get_from_fdb(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds |= mch_model_data.get_from_fdb(request_hhl_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhl = ds[\"HHL\"].squeeze(drop=True)\n",
    "hhl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Potential Vorticity\n",
    "\n",
    "The next Jupyter cell will tackle the computation of potential vorticity, a more complex process that isn't directly computed by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meteodatalab import metadata\n",
    "from meteodatalab.operators.rho import compute_rho_tot\n",
    "from meteodatalab.operators.theta import compute_theta\n",
    "from meteodatalab.operators.pot_vortic import compute_pot_vortic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = compute_theta(ds[\"P\"], ds[\"T\"])\n",
    "rho_tot = compute_rho_tot(ds[\"T\"], ds[\"P\"], ds[\"QV\"], ds[\"QC\"], ds[\"QI\"])\n",
    "\n",
    "metadata.set_origin_xy(ds, \"HHL\")\n",
    "pot_vortic = compute_pot_vortic(ds[\"U\"], ds[\"V\"], ds[\"W\"], theta, rho_tot, hhl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate to potential temperature levels\n",
    "\n",
    "It's possible to interpolate the potential vorticity on isotherms of potential temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meteodatalab.operators.destagger import destagger\n",
    "from meteodatalab.operators.vertical_interpolation import interpolate_k2theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mid-levels of hhl for the interpolation\n",
    "hfl = destagger(hhl, \"z\")\n",
    "theta_values = [310.0, 315.0, 320.0, 325.0, 330.0, 335.0]\n",
    "pot_vortic_th = interpolate_k2theta(pot_vortic, \"low_fold\", theta, theta_values, \"K\", hfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = earthkit.plots.Map(domain=domain)\n",
    "# === Load custom colormap with levels ===\n",
    "colors, levels = load_ncl_rgb_colors(\"pot_vortic\")\n",
    "\n",
    "chart.quickplot(pot_vortic_th.sel(z=320)*1e6, x=\"lon\", y=\"lat\", style=Style(colors=colors, levels=levels))\n",
    "\n",
    "# === Add Frame ===\n",
    "frame_polygon = get_valid_data_frame(data)\n",
    "\n",
    "if frame_polygon:\n",
    "    x, y = frame_polygon.exterior.xy\n",
    "    chart.ax.plot(x, y, color='black', linewidth=1, transform=ccrs.PlateCarree())\n",
    "else:\n",
    "    print(\"No valid frame polygon could be computed.\")\n",
    "\n",
    "# === Add Map Features ===\n",
    "chart.land()\n",
    "chart.coastlines()\n",
    "chart.borders()\n",
    "chart.gridlines()\n",
    "\n",
    "ref_time = pd.to_datetime(pot_vortic_th.coords[\"ref_time\"].values[0]).strftime(\"%Y-%m-%d %H:%M UTC\")\n",
    "lead_time = pot_vortic_th.coords[\"lead_time\"].values.astype('timedelta64[h]')\n",
    "\n",
    "title = f\"Potential Vorticity at $\\\\theta$ = 320K | {ref_time} (+{lead_time})\"\n",
    "legend_label = f\"potential vorticity units (PUV)\"\n",
    "\n",
    "chart.title(title)\n",
    "chart.legend(label=legend_label)\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the mean between pressure levels\n",
    "\n",
    "There's also an option to compute the mean potential vorticity between two isobars (or pressure levels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meteodatalab.operators.vertical_interpolation import interpolate_k2p\n",
    "from meteodatalab.operators.vertical_reduction import integrate_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isobars = interpolate_k2p(hfl, \"linear_in_lnp\", ds[\"P\"], [700, 900], \"hPa\")\n",
    "h700, h900 = isobars.transpose(\"z\", ...)\n",
    "pot_vortic_mean = integrate_k(pot_vortic, \"normed_integral\", \"z2z\", hhl, (h900, h700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = earthkit.plots.Map(domain=domain)\n",
    "# === Load custom colormap with levels ===\n",
    "colors, _ = load_ncl_rgb_colors(\"pot_vortic\")\n",
    "levels = [-10.0,-8.9,-7.4,-5.6,-3.6,-1.6,-0.4,-0.1,0.0,0.1,0.4,1.6,3.6,5.6,7.4,8.9,10.0]\n",
    "chart.quickplot(pot_vortic_mean*1e6, x=\"lon\", y=\"lat\", style=Style(colors=colors, levels=levels))\n",
    "\n",
    "# === Add Frame ===\n",
    "frame_polygon = get_valid_data_frame(data)\n",
    "\n",
    "if frame_polygon:\n",
    "    x, y = frame_polygon.exterior.xy\n",
    "    chart.ax.plot(x, y, color='black', linewidth=1, transform=ccrs.PlateCarree())\n",
    "else:\n",
    "    print(\"No valid frame polygon could be computed.\")\n",
    "\n",
    "# === Add Map Features ===\n",
    "chart.land()\n",
    "chart.coastlines()\n",
    "chart.borders()\n",
    "chart.gridlines()\n",
    "\n",
    "ref_time = pd.to_datetime(pot_vortic_th.coords[\"ref_time\"].values[0]).strftime(\"%Y-%m-%d %H:%M UTC\")\n",
    "lead_time = pot_vortic_th.coords[\"lead_time\"].values.astype('timedelta64[h]')\n",
    "\n",
    "title = f\"Mean potential vorticity between 900 and 700 hPa | {ref_time} (+{lead_time})\"\n",
    "legend_label = f\"potential vorticity units (PUV)\"\n",
    "\n",
    "chart.title(title)\n",
    "chart.legend(label=legend_label)\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- retrieve data from FDB in python\n",
    "- read GRIB data into xarray\n",
    "- process the data with meteorological operators that are aware of the grib metadata\n",
    "- keep the GRIB metadata consistent thoughout operations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polytope demo",
   "language": "python",
   "name": "polytope-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
